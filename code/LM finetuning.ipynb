{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e71ef0-66a2-4cd0-b66e-e058a5b72eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification, get_scheduler\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import evaluate, torch, os\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ebecf-e2d6-4357-9c75-f71f0b8542f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"topics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d6cc2-e012-4daf-820f-fef53b9ded4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =  str(gpu)\n",
    "torch.cuda.set_device(gpu) \n",
    "\n",
    "training_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bfd75-a3f2-4bfa-94ba-a764f0e3fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SciBERT parameters\n",
    "num_epochs = 5\n",
    "l_r = 5e-5\n",
    "wu = 50\n",
    "len_batch = 8\n",
    "\n",
    "#Class mapping\n",
    "label2id = {\"supertopic\": 0, \"subtopic\":1, \"same_as\": 2, \"other\": 3}\n",
    "labels_id = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4079c-3dcb-4a3d-a53f-bffe92a87acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[column], padding=\"max_length\", max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca6dfcc-f17e-4e38-91c3-6e6ff68890d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the right tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased', output_hidden_states=True)\n",
    "\n",
    "#load the dataset\n",
    "dataset = load_dataset('csv', data_files={'train': '../dataset/LM_dataset/training_set.csv', 'validation': '../dataset/LM_dataset/validation_set.csv',\n",
    "                                          'test': '../dataset/LM_dataset/testing_set.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f8114-d004-4012-9b65-af09caa7823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize data\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([column])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['subject','object'])\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "validation_dataset = tokenized_datasets[\"validation\"]\n",
    "test_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=False, batch_size=len_batch)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=len_batch)\n",
    "eval_dataloader = DataLoader(validation_dataset, shuffle=False, batch_size=len_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b23f8c-509f-4dc5-9859-4fa1772f9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=len(label2id), label2id=label2id)\n",
    "model_name =  \"ep\" + str(num_epochs) + \"_optAdam_\" + str(l_r) + \"_wu\" + str(wu) + \"_batch\" + str(len_batch)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=l_r)\n",
    "\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=wu, num_training_steps=num_training_steps)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Start training epoch (\" + str(epoch + 1) + \"/\" + str(num_epochs) + \")\")\n",
    "    \n",
    "    progress_bar = tqdm(range(len(train_dataloader) + len(eval_dataloader)))\n",
    "\n",
    "    # Performing Training for each epoch\n",
    "    training_loss = 0.\n",
    "    model.train()\n",
    "\n",
    "    i = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # The training loop\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if i % 100 == 99:  # print every 100 batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] training loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "        i = i + 1\n",
    "        \n",
    "        \n",
    "    # Performing Validation for each epoch\n",
    "    validation_loss = 0.\n",
    "    model.eval()\n",
    "\n",
    "    # The validation loop\n",
    "    j = 0\n",
    "    running_loss = 0.0\n",
    "    acc_val = 0.0\n",
    "    \n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        validation_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "        logits = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        acc_val += accuracy_score(labels, logits)\n",
    "\n",
    "        if j % 50 == 49:  # print every 50 batches\n",
    "            print(f'[{epoch + 1}, {j + 1:5d}] evaluation loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "        j = j + 1\n",
    "\n",
    "        \n",
    "    # Calculating the average training and validation loss and accuracy over epoch\n",
    "    training_loss_avg = training_loss / len(train_dataloader)\n",
    "    validation_loss_avg = validation_loss / len(eval_dataloader)\n",
    "    avg_val_accuracy = acc_val / len(eval_dataloader)\n",
    "\n",
    "    # Printing average training and average validation losses\n",
    "    print(\"Epoch: {}\".format(epoch+1))\n",
    "    print(\"Training loss: {}\".format(training_loss_avg))\n",
    "    print(\"Validation loss: {}\".format(validation_loss_avg))\n",
    "    print(\"Validation accuracy: {}\".format(avg_val_accuracy))\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch + 1,\n",
    "            'Training Loss': training_loss_avg,\n",
    "            'Valid. Loss': validation_loss_avg,\n",
    "            'Valid. Accur.': avg_val_accuracy\n",
    "        }\n",
    "    )\n",
    "    \n",
    "torch.save({\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_name + '.bin')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fcb59b-fb2e-417a-bcc9-26aeb88cc528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "df_stats.to_csv(\"Training_stats_\" + str(model_name) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f672c60-fadb-41fd-9c26-a2ced2f228f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating testing set\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\", labels=labels_id)\n",
    "recall = evaluate.load(\"recall\", labels=labels_id)\n",
    "\n",
    "real_labels_list = []\n",
    "predictions_list = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    accuracy.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    precision.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    recall.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "acc_ = accuracy.compute()\n",
    "prec_ = precision.compute(average=None)\n",
    "rec_ = recall.compute(average=None)\n",
    "\n",
    "eval_results = [round(acc_['accuracy'], 4), round(prec_['precision'][0],4),round(prec_['precision'][1],4),\n",
    "round(prec_['precision'][2],4), round(prec_['precision'][3],4),  round(rec_['recall'][0], 4),round(rec_['recall'][1], 4),\n",
    "round(rec_['recall'][2], 4),round(rec_['recall'][3], 4)]\n",
    "\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
